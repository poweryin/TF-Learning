

# 原理

分布式Tensorflow由高性能gPRC库底层技术支持

##情况一

单机多卡工作原理：每个GPU处理一个批次数据，变量参数保存在CPU，数据由CPU分发给GPU，GPU计算每个批次梯度更新，CPU搜集多个GPU更新梯度，计算平均梯度，更新参数。处理速度取决于最慢GPU速度。

## 情况二

多机多卡：

Cluster,job,task概念，task可以看成每台机器上的一个进程，多个task组成job，job又有ps,worker两种，分别同于参数服务与计算服务。组成cluster。

Tensorflow API提供了Cluster，Server,Supervisor来支持模型的分布式训练

Tensorflow 的Cluster由多个Task组成，每隔个task对应一个tf.train.server.

多个相同的task被划分为一个job，ps job 作为参数服务器保存参数，worker job作为计算节点进行图计算。

## in-graph

将数据存储到到一个节点上，训练时，要将不同的数据分到不同的机器上

## between - graph

训练的参数，保存在参数服务器，数据不用分发，数据分片的保存在各个计算节点上。

### 同步SGD与异步SGD：

同步是指：每台电脑计算完各自的batch 后，求梯度值，把梯度值统一送到ps服务器中，由ps服务器求梯度平均值，更新ps服务器上的参数。

异步更新：

ps服务器只要收到一台机器的梯度值，就直接进行参数更新，无需等待其他机器。这种方式不稳定，收敛曲线震动比较厉害，因为当A机器更新完了ps的参数后，B机器还在用上一次迭代的旧版的值。

## 代码编写：

```py
#现有多台机器，每一台由一个或多个显卡
import tensorflow as tf
# 假设现在有四台机器A,B,C,D。首先需要在各台机器上写一份代码，各台机器上的代码内容应该大部分相同
#除了一开始定义的时候，需要各自指定该台机器的task之外，以A为例子，A机器上的代码为：

cluster = tf.train.ClusterSpec({
		'worker':[
            "机器A 的IP：端口号"，
            "机器B 的IP：端口号",
            机器C 的IP：端口号,
		],
        "ps":[
            ""机器D 的IP：端口号
        ]
})
```

* 在各台机器上指定server

  ```py
  server = tf.train.Server(cluster,job_name="worker",task_index=0)#找到‘worker’名字下的，task0，也就是机器A
  ```

  

* 在代码中指定device

  ```py
  with tf.device('/job:ps/task:0'):#参数定义在机器D上
  	w=tf.get_variable('w',(2,2),tf.float32,initializer=tf.constant_initializer(2))
  	b=tf.get_variable('b',(2,2),tf.float32,initializer=tf.constant_initializer(5))
   
  with tf.device('/job:worker/task:0/cpu:0'):#在机器A cpu上运行
  	addwb=w+b
  with tf.device('/job:worker/task:1/cpu:0'):#在机器B cpu上运行
  	mutwb=w*b
  with tf.device('/job:worker/task:2/cpu:0'):#在机器C cpu上运行
  	divwb=w/b
  
  ```

* 在深度学习中，一般的图计算在每个机器上都是相同的，所以把所有图计算、变量定义等代码都写到下面语句当中：

  ```py
  with tf.device(tf.train.replica_device_setter(worker_device="/job:worker/task:index",cluster=cluster))
  ```

  函数replica_deviec_setter会自动把变量参数定义到ps服务当中（如果ps有多个任务，那么将自动分配），假设现在有两台机器，A,B。A用于计算服务，N用于参数服务，那么代码如下：

  ```py
  import tensorflow as tf
  #现在有A B 两塔机器，搜先需要在各台机器上写一份代码，运行起来，各机器上的代码大部分相同
  #除了来时定义的时候，需要各自指定该台机器的task之外。以机器A为例子：
  cluster = tf.train.Clusterspec({
      "worker":["第一台机器的IP地址：端口号"]，
      "ps":["第二台机器的IP地址：端口号"]
  })
  # 下面这一行代码各不相同，用于指定每台机器的task
  isps = False
  if isps:
  	server = tf.train.Server(cluster,job_name = 'ps',task_index = 0)
  	server.join()
  else:
  	server = tf.trian.Server(cluster,job_namne="worker",task_index=0)
  	with  tf.device(tf.train.replica_device_setter(
  	worker_device='/job:worker/task:0',cluster=cluster)
  	):
  		w=tf.get_variable('w',(2,2),tf.float32,initializer=tf.constant_initializer(2))
  		b=tf.get_variable('b',(2,2),tf.float32,initializer=tf.constant_initializer(5))
  		addwb=w+b
  		mutwb=w*b
  		divwb=w/b
  
  saver = tf.train.Saver()
  summary_op = tf.merge_all_summaries()
  init_op = tf.initialize_all_variables()
  sv = tf.train.Supervisor(init_op = init_op,summary_op=summary_op, saver=saver)
  with sv.managed_session(server.target) as sess:
  	while 1:
  		print sess.run([addwb,mutwb,divwb])
  	
  ```

  把该代码在机器A上运行，程序会进入等候状态，等候用于ps参数服务器的机器启动，才会运行。机器B 上的代码为：

  ```py
  #coding=utf-8
  #上面是因为worker计算内容各不相同，不过再深度学习中，一般每个worker的计算内容是一样的，
  # 以为都是计算神经网络的每个batch 前向传导，所以一般代码是重用的
  #coding=utf-8
  #多台机器，每台机器有一个显卡、或者多个显卡，这种训练叫做分布式训练
  import  tensorflow as tf
  #现在假设我们有A、B、C、D四台机器，首先需要在各台机器上写一份代码，并跑起来，各机器上的代码内容大部分相同
  # ，除了开始定义的时候，需要各自指定该台机器的task之外。以机器A为例子，A机器上的代码如下：
  cluster=tf.train.ClusterSpec({
      "worker": [
          "192.168.11.105:1234",#格式 IP地址：端口号，第一台机器A的IP地址 ,在代码中需要用这台机器计算的时候，就要定义：/job:worker/task:0
      ],
      "ps": [
          "192.168.11.130:2223"#第四台机器的IP地址 对应到代码块：/job:ps/task:0
      ]})
   
  #不同的机器，下面这一行代码各不相同，server可以根据job_name、task_index两个参数，查找到集群cluster中对应的机器
   
  isps=True
  if isps:
  	server=tf.train.Server(cluster,job_name='ps',task_index=0)#找到‘worker’名字下的，task0，也就是机器A
  	server.join()
  else:
  	server=tf.train.Server(cluster,job_name='worker',task_index=0)#找到‘worker’名字下的，task0，也就是机器A
  	with tf.device(tf.train.replica_device_setter(worker_device='/job:worker/task:0',cluster=cluster)):
  		w=tf.get_variable('w',(2,2),tf.float32,initializer=tf.constant_initializer(2))
  		b=tf.get_variable('b',(2,2),tf.float32,initializer=tf.constant_initializer(5))
  		addwb=w+b
  		mutwb=w*b
  		divwb=w/b
   
  saver = tf.train.Saver()
  summary_op = tf.merge_all_summaries()
  init_op = tf.initialize_all_variables()
  sv = tf.train.Supervisor(init_op=init_op, summary_op=summary_op, saver=saver)
  with sv.managed_session(server.target) as sess:
   
  	while 1:
  		print sess.run([addwb,mutwb,divwb])
  
  ```

## Ring-allreduce结构

在此结构中，不存在给worker提供聚合梯度计算的中心化服务器，在每次迭代中，每个工作设备读取mini-batch中属于自己的那一部分，计算梯度，将梯度发送到环节上的后继节点，并从环上的一个临近节点接收梯度。

当环上一共由N台机器时，需要经过N-1次迭代，将自己的梯度传到下一节点，自己接收上一节点的梯度。

## Horovod

Tnesorflow有两个可用的ring-allreduce框架 tensorflow.contrib.mpi_collectives ，和来自Uber的Horovod 。

使用pip安装

依赖库：Open MPI, NCCL-2

1. 安装NCCL2:https://docs.nvidia.com/deeplearning/sdk/nccl-install-guide/index.html#downloadnccl

如果使用的是安装包安装，需要将路径添加到path中

```
$ export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/nccl-<version>/lib
```

NCCL2中可以使用GPUDirect,使得可以直接在多个GPU之间交换数据，而不用通过CPU

2. 安装Open MPI,是一种高速信息传递库。

   1) 首先需要设置这两台机器可以互相免密登陆。

   ​	使用ssh-keygen 工具创建密钥

   ​	ssh-keygen -t rsa

   ​        使用ssh-copy-id命令自动在目标服务器上生成~/.ssh/authorized_keys 文件

   ​       ssh-copy-id -i ~/.ssh/id_rsa.pub dss@ip地址

   2) 安装openmpi

​               下载安装包

```
wget -c https://download.open-mpi.org/release/open-mpi/v3.1/openmpi-3.1.3.tar.gz
```

​       3) 安装：

```
tar zxvf openmpi-3.1.3.tar.gz
cd openmpi-3.1.3
./configure --prefix=/opt/openmi
make
sudo make install 
```

​      4)设置环境变量

```
export PATH=$PATH:/opt/openmpi/bin
export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/openmpi/lib/
```

​       并将其写入~/.bashrc文件中，这样mpiexec在远程机器上运行的时候就会自动source环境了 。

```
PATH=$PATH:/opt/openmpi/bin
LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/opt/openmpi/lib/
export PATH LD_LIBRARY_PATH
```

3. 安装horovod

   使用pip 进行安装

   如果使用安装包安装的NCCL2 ，需要设置`HOROVOD_NCCL_HOME `环境变量

   ```
   HOROVOD_NCCL_HOME=/usr/local/nccl-<version> HOROVOD_GPU_ALLREDUCE=NCCL pip install --no-cache-dir horovod
   ```

   如果使用的是ubantu包安装的，则需要使用：

   ```
   HOROVOD_GPU_ALLREDUCE=NCCL pip install --no-cache-dir horovod
   ```

   **NOTE**  强制allreduce在cpu上运行：

   ```
   opt = hvd.DistributedOptimizer(opt,device_dence="/cpu:0")
   ```

4. 在GPU上实现数据传递：
   如果，MPI的allreduce实现是基于GPU的，他的速度比NCCL快，那么可以使用以下代码设置horovod

```
 HOROVOD_GPU_ALLREDUCE=MPI pip install --no-cache-dir horovod
```

​	如果MPI支持，在GPU上执行allgather和brocast，可以进行如下设置：

```
HOROVOD_GPU_ALLREDUCE=MPI HOROVOD_GPU_ALLGATHER=MPI HOROVOD_GPU_BROADCAST=MPI pip install --no-cache-dir horovod
```

​     这样可能导致GPU的内存溢出，可以强制allreduce在CPU上运行。

之后在代码上进行如下修改：

1. Run `hvd.int()`

2. 使用`config.gpu_options.visable_device_list`固定一个进程的GPU，可以使用 local rank，这样可以使第一个进程分配给第一个GPU，第二个分配给第二个GPU。

3. 根据woker的数量调整batch_Szie的大小，以及学习率的大小。batch增加的同时，学习率也需要增加。

4. 使用`hvd.DistributeOptimizer`包裹优化算法，分布式优化将会延迟更新参数，在使用allreduce,allgather后，将所有设备上的梯度进行融合，再分发到不同的设备上。

5. 是用`hvd.BroadcastGlobalVariablesHook(0)`将初始化的参数广播到其他设备上。如果没有使用`MonitoredTrainingSession `，仅需在global variables 初始化之后，执`hvd.broadcast_global_variables`

6. 更改存储代码，使得仅在worker0上保存参数，通过使用

   `checkpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None `

   ```
   with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,
                                          config=config,
                                          hooks=hooks) as mon_sess:
   ```

代码示例：[完整代码示例](https://github.com/uber/horovod/tree/master/examples)

```
import tensorflow as tf
import horovod.tensorflow as hvd


# Initialize Horovod
hvd.init()

# Pin GPU to be used to process local rank (one GPU per process)
config = tf.ConfigProto()
config.gpu_options.visible_device_list = str(hvd.local_rank())

# Build model...
loss = ...
opt = tf.train.AdagradOptimizer(0.01 * hvd.size())

# Add Horovod Distributed Optimizer
opt = hvd.DistributedOptimizer(opt)

# Add hook to broadcast variables from rank 0 to all other processes during
# initialization.
hooks = [hvd.BroadcastGlobalVariablesHook(0)]

# Make training operation
train_op = opt.minimize(loss)

# Save checkpoints only on worker 0 to prevent other workers from corrupting them.
checkpoint_dir = '/tmp/train_logs' if hvd.rank() == 0 else None

# The MonitoredTrainingSession takes care of session initialization,
# restoring from a checkpoint, saving to a checkpoint, and closing when done
# or an error occurs.
with tf.train.MonitoredTrainingSession(checkpoint_dir=checkpoint_dir,
                                       config=config,
                                       hooks=hooks) as mon_sess:
  while not mon_sess.should_stop():
    # Perform synchronous training.
    mon_sess.run(train_op)
```

运行分布式训练:[参考](https://github.com/uber/horovod/blob/master/docs/running.md#open-mpi-with-rdma)

在open MPI的基础上运行分布式训练

使用的命令为mpirun

每一个GOU将会分配一个进程，假设有4个GPU，那么就需要分配四个进程，使用`-np num`来设置Gpu数量

-bind-to none :不要将一个训练进程绑定到一个GPU

-map-by slot :允许将参数混合

``-mca pml ob1` and `-mca btl ^openib``强迫使用TCP在MPI之间通信。这样并不会影响计算速度，因为大量的计算由NCCL完成。但是当经常的使用 ``hvd.broadcast()` and `hvd.allgather()` `,就不一样了，需要启动RDMA。（在下面讲解到）

使用-x可以使得指定一个或者copy一个变量到所有workers

例子：

一台机器上的4个GPU

```
mpirun -np 4 \
	-H localhost:4\
	-bind-to none -map-by slot\
	-x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \
    -mca pml ob1 -mca btl ^openib \
    python train.py
```

四台机器上，每台4个GPU

```
 mpirun -np 16 \
    -H server1:4,server2:4,server3:4,server4:4 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH \
    -mca pml ob1 -mca btl ^openib \
    python train.py
```

使用RDMA

必须设置 `-x HOROVOD_MPI_THREADS_DISABLE=1 `

```
mpirun -np 16 \
    -H server1:4,server2:4,server3:4,server4:4 \
    -bind-to none -map-by slot \
    -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x HOROVOD_MPI_THREADS_DISABLE=1 -x PATH \
    -mca pml ob1 \
    python train.py
```



## Kubernetes（k8s）[参考](http://www.dockone.io/article/932)



相当于比docker更高级 的容器操作，使得分布式训练

框架如下图所示：![1.png](分布式训练.assets/d56441427680948fb56a00af57bda690.png)


 

### pod

包含一组容器和卷，同一个Pod中的容器共享一个网络命名空间，可以使用localhost相互通信。

- 如果Pod是短暂的，那么我怎么才能持久化容器数据使其能够跨重启而存在呢？ 是的，Kubernetes支持[卷](http://kubernetes.io/v1.1/docs/user-guide/volumes.html)的概念，因此可以使用持久化的卷类型。
- 是否手动创建Pod，如果想要创建同一个容器的多份拷贝，需要一个个分别创建出来么？可以手动创建单个Pod，但是也可以使用Replication Controller使用Pod模板创建出多份拷贝，下文会详细介绍。
- 如果Pod是短暂的，那么重启时IP地址可能会改变，那么怎么才能从前端容器正确可靠地指向后台容器呢？这时可以使用Service，下文会详细介绍。

### Label

一个Pod有Label,一个label是attach到pod的一个键值，用来表示用户定义的属性，比如，你可能创建了一个"tier"和“app”标签，通过Label（**tier=frontend, app=myapp**）来标记前端Pod容器，使用Label（**tier=backend, app=myapp**）标记后台Pod 。可以使用selectors选择带有特定label的pod。并且将Serivce或者Replication Controller应用到上面 。

### Replication Controller

Replication Controller确保任意时间都有指定数量的Pod“副本”在运行。如果为某个Pod创建了Replication Controller并且指定3个副本，它会创建3个Pod，并且持续监控它们。如果某个Pod不响应，那么Replication Controller会替换它，保持总数为3.如下面的动画所示： 

![img](分布式训练.assets/5e2bad1a25e33e2d155da81da1d3a54b.gif)

 如果之前不响应的Pod恢复了，现在就有4个Pod了，那么Replication Controller会将其中一个终止保持总数为3。如果在运行中将副本总数改为5，Replication Controller会立刻启动2个新Pod，保证总数为5。还可以按照这样的方式缩小Pod，这个特性在执行滚动[升级](https://cloud.google.com/container-engine/docs/replicationcontrollers/#rolling_updates)时很有用。  



当创建Replication Controller时，需要指定两个东西：

 

1. [Pod模板](http://kubernetes.io/v1.1/docs/user-guide/replication-controller.html#pod-template)：用来创建Pod副本的模板
2. [Label](http://kubernetes.io/v1.1/docs/user-guide/replication-controller.html#labels)：Replication Controller需要监控的Pod的标签。

 

现在已经创建了Pod的一些副本，那么在这些副本上如何均衡负载呢？我们需要的是Service。

### Service 

Pods是短暂的，重启时Ip会改变，怎样才能从前端容器正确可靠的指向后台容器。

Service定义一系列Pod以及访问这些pod的策略的抽象，Service通过Label找到pod。

现在，假定有2个后台Pod，并且定义后台Service的名称为‘backend-service’，lable选择器为（**tier=backend, app=myapp**）。*backend-service* 的Service会完成如下两件重要的事情： 

* 为Service创建一个本地集群的DNS入口，因此前端pod只需要DNS查找主机名为backend-service’，就能够解析出前端应用程序可用的IP地址。 

* 现在前端已经得到了后台服务的IP地址，到那时他因该访问2个后台pod的哪一个呢？Service在这两个后台pod之间提供透明的负载均衡，会将请求发送给其中任何一个，通过每隔Node运行的代理（kube-proxy）完成

  

  下述动画展示了Service的功能。注意该图作了很多简化。如果不进入网络配置，那么达到透明的负载均衡目标所涉及的底层网络和路由相对先进。如果有兴趣，[这里](http://www.dasblinkenlichten.com/kubernetes-101-networking/)有更深入的介绍。 

![img](分布式训练.assets/125bbccce0b3bbf42abab0e520d9250b.gif) 有一个特别类型的Kubernetes Service，称为'[LoadBalancer](http://kubernetes.io/v1.1/docs/user-guide/services.html#type-loadbalancer)'，作为外部负载均衡器使用，在一定数量的Pod之间均衡流量。比如，对于负载均衡Web流量很有用 



### Node

节点（上图橘色方框）是物理或者虚拟机器，作为Kubernetes worker，通常称为Minion。 每个节点都运行如下Kubernetes关键组件：

 

- Kubelet：是主节点代理。
- Kube-proxy：Service使用其将链接路由到Pod，如上文所述。
- Docker或Rocket：Kubernetes使用的容器技术来创建容器。



### Kubernetes Master

集群拥有一个Kubernetes Master（紫色方框）。Kubernetes Master提供集群的独特视角，并且拥有一系列组件，比如Kubernetes API Server。API Server提供可以用来和集群交互的REST端点。master节点包括用来创建和复制Pod的Replication Controller。

### 还需要学习的连接

https://github.com/IBM/FfDL/tree/master/etc/examples/horovod/

https://kubernetes.io/zh/docs/tutorials/kubernetes-basics/
